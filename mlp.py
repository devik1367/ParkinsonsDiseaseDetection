# -*- coding: utf-8 -*-
"""mlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R_8ps-RWhZsV_-1ONixkwunVuUqhnHYu
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import SelectFromModel

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error
import math


import numpy
import pandas
import tensorflow as tf
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler
from tensorflow import keras
from tensorflow.keras import layers


def load_data(path):
    parkinsons_data = pd.read_csv(path)

    X = parkinsons_data.drop(['total_UPDRS', 'motor_UPDRS'], axis=1)
    y = parkinsons_data.loc[:, 'total_UPDRS']

   
    #y2 = parkinsons_data.loc[:, 'motor_UPDRS']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

    return X_train, X_test, y_train, y_test


def random_forest_features(X_train, y_train, X_test):

    model = SelectFromModel(RandomForestRegressor(n_estimators=1000))
    model.fit(X_train, y_train)

    selected_feat = X_train.columns[(model.get_support())]

    print("Attributes selected are " + str(selected_feat))

    X_train = X_train[selected_feat]
    X_test = X_test[selected_feat]

    return X_train, X_test


def pca_features(X_train, X_test):
    scalar = StandardScaler()
    scalar.fit(X_train)

    X_train = scalar.transform(X_train)
    X_test = scalar.transform(X_test)

    pca = PCA(0.95)
    pca.fit(X_train)

    print("number of principal components selected are " + str(pca.n_components_))
    # print(pca.components_)

    X_train = pca.transform(X_train)
    X_test = pca.transform(X_test)

    X_train = pd.DataFrame(data=X_train)
    X_test = pd.DataFrame(data=X_test)

    return X_train, X_test




def mlp():
   
    X_train, X_test, y_train, y_test = load_data('./parkinsons_updrs.data')
    X_train, X_test = random_forest_features(X_train, y_train, X_test)
                                                  
    print(y_test)
    hidden_units = [500, 400, 300, 200]
    activation = 'sigmoid'
    lr = 0.0005

    

    total_results, motor_results = [], []
    K = 5
    
    for i in range(K):
        
        model = keras.Sequential()
        for layer in range(len(hidden_units)):
            model.add(layers.Dense(units=hidden_units[layer], activation=activation))
        # 2 units in the output layer (Total and Motor)
        model.add(layers.Dense(units=1))
        optimizer = tf.keras.optimizers.Adam(lr)
        model.compile(loss='mse',
                      optimizer=optimizer,
                      metrics=['mae', 'mse'])

        history = model.fit(x=X_train,
                            y=y_train,
                            epochs=1000,
                            validation_split=0.1,
                            verbose=0,
                            callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)])

        y_pred = model.predict(X_test)
        print(y_pred)
        mae_total = mean_absolute_error(y_test, y_pred)
        #mae_motor = mean_absolute_error(y_test, y_pred)
        total_results.append(mae_total)
        #motor_results.append(mae_motor)

    print(total_results)
    #print(motor_results)
    print(sum(total_results)/len(total_results))
    #print(sum(motor_results)/len(motor_results))
    

mlp()
